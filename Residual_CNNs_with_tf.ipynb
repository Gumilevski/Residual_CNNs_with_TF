{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZjVxvlGX_oT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before building/training/... model, let's implement some extra auxiliary methods**\n",
    "\n",
    "\n",
    "1) **run_model** is the main function to run the model over some number of **epochs**. **Xd, yd** is your training data and **X_val, y_val** is your validation set. If you are training, you can set **print_every** by some value to see every **print_every** iterations current loss and accuracy. Set **plot_losses** by **True** value if you want to plot the dependency of training losses on the iteration number and set **plot_accuracies** by **True** value if you want to plot the dependency of training and validation accuracy on the epoch number. (note that training accuracy is in blue and validation accuracy is in red).\n",
    "\n",
    "2) **run_model_per_epoch** - this function is used in the implementation of **run_model**. It runs the model on one epoch. Also can be used to test your model on validation/test sets.\n",
    "\n",
    "3) **generate_indicies** is just small auxiliary method, which is used in **run_model_per_epoch**. This method returns some inidicies to generate mini-batch from X of some **batch_size**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bb-DsTCYZOa"
   },
   "outputs": [],
   "source": [
    "def generate_indicies(X, iter_num, batch_size, indicies):\n",
    "  start_idx = (iter_num * batch_size) % X.shape[0] \n",
    "  end_idx = (start_idx + batch_size) % X.shape[0] \n",
    "\n",
    "  if end_idx < start_idx:\n",
    "    start_idx, end_idx = 0, batch_size\n",
    "\n",
    "  return indicies[start_idx:end_idx]\n",
    "\n",
    "def run_model_per_epoch(session, prediction, Xd, yd, epoch_num, batch_size=64, \n",
    "                        print_every=200, training=None):\n",
    "    \n",
    "    iterations_per_epoch = int(Xd.shape[0] / batch_size)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), y) \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(indicies)\n",
    "\n",
    "    training_now = training is not None \n",
    "    #training_now is False if the model isn't training \n",
    "    # on current epoch and True otherwise\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    correct = 0 #number of correct predictions\n",
    "    losses = [] #losses on each iteration of the epoch \n",
    "    for i in range(int(math.ceil(Xd.shape[0] / batch_size))):\n",
    "      # generate indicies for the batch\n",
    "      idx = generate_indicies(Xd, i, batch_size, indicies)\n",
    "            \n",
    "      # create a feed dictionary for this batch\n",
    "      feed_dict = {X: Xd[idx, :],\n",
    "                   y: yd[idx],\n",
    "                   is_training: training_now }\n",
    "      # have tensorflow compute loss and correct predictions\n",
    "      # and (if given) perform a training step\n",
    "      loss_sess, corr, _ = session.run(variables, feed_dict=feed_dict)\n",
    "            \n",
    "      losses.append(loss_sess * batch_size)\n",
    "      correct += np.sum(corr)\n",
    "      \n",
    "      training_iteration = iterations_per_epoch * (epoch_num - 1) + i\n",
    "      #training_iteration is current training iteration number\n",
    "      if training_now and training_iteration % print_every == 0:\n",
    "          print(f'Iteration {training_iteration}:\\\n",
    "                with minibatch training loss = {loss_sess}\\\n",
    "                and accuracy of {np.round(np.sum(corr) / batch_size, 4)}')\n",
    "\n",
    "    total_correct = correct / Xd.shape[0] #accuracy on the epoch\n",
    "    total_loss = np.sum(losses) / Xd.shape[0] #total loss on the epoch\n",
    "    \n",
    "    print(f'Epoch {epoch_num}, Total loss = {total_loss} \\\n",
    "    and accuracy of {np.round(total_correct, 4)}')\n",
    "\n",
    "    return losses, total_correct\n",
    "  \n",
    "  \n",
    "def run_model(session, prediction, Xd, yd, X_val, y_val, epochs=15, batch_size=64,\n",
    "              print_every=200, plot_losses=True, plot_accuracies=True):\n",
    "  print(f'Training over {epochs} epochs')\n",
    "  train_losses = [] #will be used to plot the depency of train_losses on iteration number\n",
    "  train_accuracy = [] #will be used to plot the depency of train_accuracy on epoch number\n",
    "  validation_accuracy = [] ##will be used to plot the depency of validation_accuracy on epoch number\n",
    "  \n",
    "  for i in range(epochs):\n",
    "    print(f'Epoch {i+1}:')\n",
    "    epoch_tr_losses, epoch_train_acc = run_model_per_epoch(session, prediction, \n",
    "                                                           Xd, yd, i+1, batch_size, \n",
    "                                                           print_every, train_step)\n",
    "    train_losses += epoch_tr_losses \n",
    "    train_accuracy += [epoch_train_acc]\n",
    "          \n",
    "    print('\\nValidation:')\n",
    "    _, epoch_val_acc = run_model_per_epoch(session, prediction, X_val, y_val, \n",
    "                                           i+1, batch_size)\n",
    "    validation_accuracy += [epoch_val_acc]\n",
    "          \n",
    "    print('\\n')\n",
    "          \n",
    "  if plot_losses:\n",
    "    plt.plot(train_losses)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Loss History')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "            \n",
    "  if plot_accuracies:\n",
    "    plt.plot(train_accuracy, 'b', validation_accuracy, 'r')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Train/Validation accuracy per epoch')\n",
    "    plt.xlabel('Epoch') \n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below the data will be **loaded**, **splitted into train/val/test sets** and **preprocessed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "NLUCLvdOYrl1",
    "outputId": "4859885c-7350-4dfc-f799-21a4851a680a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (40000, 32, 32, 3) , dtype:  float32\n",
      "Train labels shape:  (40000,) dtype:  int64\n",
      "Validation data shape:  (10000, 32, 32, 3) dtype:  float32\n",
      "Validation labels shape:  (10000,) dtype:  int64\n",
      "Test data shape:  (10000, 32, 32, 3) dtype:  float32\n",
      "Test labels shape:  (10000,) dtype:  int64\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() #loading data\n",
    "\n",
    "TRAIN_SIZE = 50_000\n",
    "TEST_SIZE = 10_000\n",
    "val_part = 0.2 \n",
    "train_part = 1 - val_part\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = val_part) #train/validation split\n",
    "X_train, X_val, X_test = np.array(X_train, dtype=np.float32), np.array(X_val, dtype=np.float32), (\n",
    "                         np.array(X_test, dtype=np.float32))\n",
    "\n",
    "y_train = np.reshape(y_train, int(TRAIN_SIZE * train_part))\n",
    "y_val = np.reshape(y_val, int(TRAIN_SIZE * val_part))\n",
    "y_test = np.reshape(y_test, TEST_SIZE)\n",
    "y_train, y_val, y_test = np.array(y_train, dtype=np.int64), np.array(y_val, dtype=np.int64), np.array(y_test, dtype=np.int64)\n",
    "\n",
    "#data preprocessing\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "mean_image = np.mean(X_val, axis=0)\n",
    "X_val -= mean_image \n",
    "mean_image = np.mean(X_test, axis=0)\n",
    "X_test -= mean_image \n",
    "\n",
    "print('Train data shape: ', X_train.shape, ', dtype: ', X_train.dtype)\n",
    "print('Train labels shape: ', y_train.shape, 'dtype: ', y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape, 'dtype: ', X_val.dtype)\n",
    "print('Validation labels shape: ', y_val.shape, 'dtype: ', y_val.dtype)\n",
    "print('Test data shape: ', X_test.shape, 'dtype: ', X_test.dtype)\n",
    "print('Test labels shape: ', y_test.shape, 'dtype: ', y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's build and train our model!**\n",
    "\n",
    "The following model will be based on **ResNet architecture**, to learn more about this architecture, follow one of the links below:\n",
    "\n",
    "1) https://arxiv.org/pdf/1603.05027.pdf\n",
    "\n",
    "2) https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's first implement some auxiliary methods**\n",
    "\n",
    "In **residual networks** activation functions usually look like **y = f(x) + x** (follow one of this links above to learn why it's useful). \n",
    "\n",
    "In the implemantation below we have **y = f(x) + dropout(x)** (if we set dropout=True), where f(x) is the sequence of **such layers**: \n",
    "\n",
    "**batch normalization - activation(relu) - 3x3 convolutional layer with stride of 1 and some variable number of filters - batch norm - relu - conv layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dropout_residual_unit** implements the structure described above. Set **dropout by True value** to use activation like y = f(x) + dropout(x) with some dropout probability **dropout_prob**.\n",
    "\n",
    "**residual_block** implements the set of residual units. It consists of **num_inits**  residual units. Number of filters in the convolutional layer of the unit is constant for the block and equals **num_filters**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5T0q_Ay0ZHBJ"
   },
   "outputs": [],
   "source": [
    "def dropout_residual_unit(input_layer, unit_num, is_training, num_filters,\n",
    "                          initializer, dropout=True, dropout_prob=0.5): \n",
    "  \n",
    "    with tf.variable_scope(\"res_unit\"+str(unit_num), reuse=tf.AUTO_REUSE):\n",
    "        first_batch = tf.layers.batch_normalization(inputs=input_layer, \n",
    "                                                training=is_training)\n",
    "        first_relu = tf.nn.relu(first_batch)\n",
    "        first_conv = tf.layers.conv2d(inputs=first_relu, filters=num_filters,  \n",
    "                                      kernel_size=[3, 3], padding='same', \n",
    "                                      activation=None, \n",
    "                                      kernel_initializer=initializer)\n",
    "        second_batch = tf.layers.batch_normalization(inputs=first_conv, \n",
    "                                              training=is_training)\n",
    "        second_relu = tf.nn.relu(second_batch)\n",
    "        second_conv = tf.layers.conv2d(inputs=second_relu, filters=num_filters, \n",
    "                                       kernel_size=[3, 3], activation=None,\n",
    "                                       padding='same', \n",
    "                                       kernel_initializer=initializer)\n",
    "        if dropout:\n",
    "            input_layer = tf.nn.dropout(input_layer, keep_prob=dropout_prob)\n",
    "        output = input_layer + second_conv\n",
    "    return output\n",
    "    \n",
    "def residual_block(input_layer, block_num, is_training, \n",
    "                   num_filters, num_units, initializer, \n",
    "                   dropout=True, dropout_prob=0.5):\n",
    "    residual_block = {}\n",
    "    with tf.variable_scope(f'Residual_block_{block_num}', reuse=tf.AUTO_REUSE):\n",
    "        residual_block[0] = dropout_residual_unit(input_layer, 0, is_training,\n",
    "                                                 num_filters, initializer, \n",
    "                                                 dropout, dropout_prob)\n",
    "        for i in range(1, num_units):\n",
    "            residual_block[i] = dropout_residual_unit(residual_block[i-1], i, \n",
    "                                                      is_training, num_filters, \n",
    "                                                      initializer, dropout, \n",
    "                                                      dropout_prob)\n",
    "    return residual_block[num_units - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to define the architecture of the model.\n",
    "\n",
    "**The architecture of the model:**\n",
    "\n",
    "1) 3x3 Convolutional layers with 16 filters and stride of 1\n",
    "\n",
    "2) Batch Normalization layer (**batch norm** below)\n",
    "\n",
    "3) ReLU Activation Layer (**relu** below)\n",
    "\n",
    "4) 5 residual blocks(with 5 units in each block) with conv - batch norm - relu after each block. The number of filters in the convolutions of each block is specified in **filters** tuple\n",
    "\n",
    "5) conv - batch norm - relu - conv - batch norm\n",
    "\n",
    "6) Fully-connected layer from 160 inputs to 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdVnqG3NZYaL"
   },
   "outputs": [],
   "source": [
    "def complex_model(X, y, is_training): \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    residual_blocks = {}\n",
    "    filters = (16, 32, 64, 128, 256) \n",
    "    \n",
    "    first_conv = tf.layers.conv2d(X, 16, [3, 3], padding='same', activation=None, \n",
    "                                  kernel_initializer=initializer)\n",
    "    first_batch = tf.layers.batch_normalization(inputs=first_conv, \n",
    "                                                training=is_training)\n",
    "    relu_layer = tf.nn.relu(first_batch)\n",
    "    for i in range(5):\n",
    "        residual_blocks[i] = residual_block(relu_layer, i, is_training, filters[i],\n",
    "                                           5, initializer, dropout=True)\n",
    "        if i != 4:\n",
    "            conv = tf.layers.conv2d(inputs=residual_blocks[i], filters=filters[i+1],\n",
    "                                    kernel_size=[5, 5], strides=1, padding='valid',\n",
    "                                    activation=None, kernel_initializer=initializer)\n",
    "            batch_norm = tf.layers.batch_normalization(inputs=conv, \n",
    "                                                       training=is_training)\n",
    "            relu_layer = tf.nn.relu(batch_norm)\n",
    "    pre_last_conv = tf.layers.conv2d(residual_blocks[4], 64, [5, 5], strides=1,\n",
    "                                 padding='valid', activation=None, \n",
    "                                 kernel_initializer=initializer) \n",
    "    pre_last_batch = tf.layers.batch_normalization(inputs=pre_last_conv, \n",
    "                                               training=is_training)\n",
    "    relu_layer = tf.nn.relu(pre_last_batch)\n",
    "    last_conv = tf.layers.conv2d(relu_layer, 10, [3, 3], strides=3,\n",
    "                                 padding='valid', activation=None, \n",
    "                                 kernel_initializer=initializer) \n",
    "    last_batch = tf.layers.batch_normalization(inputs=last_conv, \n",
    "                                               training=is_training)\n",
    "    \n",
    "    flatten = tf.reshape(last_batch, [-1, 160])\n",
    "    preds = tf.layers.dense(flatten, 10, activation=None,\n",
    "                             kernel_initializer=initializer)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**\n",
    "\n",
    "In the cell below we'll initialize our variables and create a session to train the model over 50 epochs. \n",
    "\n",
    "As a result of training, we have 73 % accuracy on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9972
    },
    "colab_type": "code",
    "id": "b2De8gwbOlBG",
    "outputId": "72228b23-ce6b-46e0-d0b5-dcfef7a047e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training over 50 epochs\n",
      "Epoch 1:\n",
      "Iteration 0:    with minibatch training loss = 2.9681596755981445    and accuracy of 0.0938\n",
      "Iteration 200:    with minibatch training loss = 2.1040139198303223    and accuracy of 0.2031\n",
      "Iteration 400:    with minibatch training loss = 1.8986189365386963    and accuracy of 0.2344\n",
      "Iteration 600:    with minibatch training loss = 1.6684092283248901    and accuracy of 0.3125\n",
      "Epoch 1, Total loss = 2.0496471435546875     and accuracy of 0.2127\n",
      "\n",
      "Validation:\n",
      "Epoch 1, Total loss = 2.609995323181152     and accuracy of 0.2317\n",
      "\n",
      "\n",
      "Epoch 2:\n",
      "Iteration 800:    with minibatch training loss = 1.93731689453125    and accuracy of 0.2812\n",
      "Iteration 1000:    with minibatch training loss = 1.9824458360671997    and accuracy of 0.3438\n",
      "Iteration 1200:    with minibatch training loss = 1.8740043640136719    and accuracy of 0.2188\n",
      "Epoch 2, Total loss = 1.8032358083724975     and accuracy of 0.3066\n",
      "\n",
      "Validation:\n",
      "Epoch 2, Total loss = 2.2520023239135742     and accuracy of 0.2904\n",
      "\n",
      "\n",
      "Epoch 3:\n",
      "Iteration 1400:    with minibatch training loss = 1.669218897819519    and accuracy of 0.375\n",
      "Iteration 1600:    with minibatch training loss = 1.7589762210845947    and accuracy of 0.3438\n",
      "Iteration 1800:    with minibatch training loss = 1.6979612112045288    and accuracy of 0.3906\n",
      "Epoch 3, Total loss = 1.7120780603408814     and accuracy of 0.3599\n",
      "\n",
      "Validation:\n",
      "Epoch 3, Total loss = 1.8172165855407716     and accuracy of 0.3505\n",
      "\n",
      "\n",
      "Epoch 4:\n",
      "Iteration 2000:    with minibatch training loss = 1.5695396661758423    and accuracy of 0.4062\n",
      "Iteration 2200:    with minibatch training loss = 1.4871375560760498    and accuracy of 0.4688\n",
      "Iteration 2400:    with minibatch training loss = 1.3488391637802124    and accuracy of 0.5781\n",
      "Epoch 4, Total loss = 1.6245666135787964     and accuracy of 0.3972\n",
      "\n",
      "Validation:\n",
      "Epoch 4, Total loss = 1.6982507514953613     and accuracy of 0.4078\n",
      "\n",
      "\n",
      "Epoch 5:\n",
      "Iteration 2600:    with minibatch training loss = 1.4210296869277954    and accuracy of 0.5156\n",
      "Iteration 2800:    with minibatch training loss = 1.5870243310928345    and accuracy of 0.4844\n",
      "Iteration 3000:    with minibatch training loss = 1.5330332517623901    and accuracy of 0.375\n",
      "Epoch 5, Total loss = 1.512871484565735     and accuracy of 0.4395\n",
      "\n",
      "Validation:\n",
      "Epoch 5, Total loss = 1.8896313957214355     and accuracy of 0.4142\n",
      "\n",
      "\n",
      "Epoch 6:\n",
      "Iteration 3200:    with minibatch training loss = 1.5047796964645386    and accuracy of 0.4688\n",
      "Iteration 3400:    with minibatch training loss = 1.4262725114822388    and accuracy of 0.4062\n",
      "Iteration 3600:    with minibatch training loss = 1.3739012479782104    and accuracy of 0.5625\n",
      "Epoch 6, Total loss = 1.419542412853241     and accuracy of 0.4762\n",
      "\n",
      "Validation:\n",
      "Epoch 6, Total loss = 1.4859859992980957     and accuracy of 0.4727\n",
      "\n",
      "\n",
      "Epoch 7:\n",
      "Iteration 3800:    with minibatch training loss = 1.6151621341705322    and accuracy of 0.4375\n",
      "Iteration 4000:    with minibatch training loss = 1.3312578201293945    and accuracy of 0.4844\n",
      "Iteration 4200:    with minibatch training loss = 1.4939115047454834    and accuracy of 0.375\n",
      "Epoch 7, Total loss = 1.3492192636489868     and accuracy of 0.5052\n",
      "\n",
      "Validation:\n",
      "Epoch 7, Total loss = 1.4598893157958985     and accuracy of 0.492\n",
      "\n",
      "\n",
      "Epoch 8:\n",
      "Iteration 4400:    with minibatch training loss = 1.3389232158660889    and accuracy of 0.5781\n",
      "Iteration 4600:    with minibatch training loss = 1.2353414297103882    and accuracy of 0.5312\n",
      "Iteration 4800:    with minibatch training loss = 1.5385533571243286    and accuracy of 0.5\n",
      "Epoch 8, Total loss = 1.2958683789253236     and accuracy of 0.5242\n",
      "\n",
      "Validation:\n",
      "Epoch 8, Total loss = 1.3238477237701416     and accuracy of 0.5246\n",
      "\n",
      "\n",
      "Epoch 9:\n",
      "Iteration 5000:    with minibatch training loss = 1.3472096920013428    and accuracy of 0.4844\n",
      "Iteration 5200:    with minibatch training loss = 1.1730002164840698    and accuracy of 0.5\n",
      "Iteration 5400:    with minibatch training loss = 1.2879925966262817    and accuracy of 0.625\n",
      "Iteration 5600:    with minibatch training loss = 1.2093660831451416    and accuracy of 0.5312\n",
      "Epoch 9, Total loss = 1.2460763718605041     and accuracy of 0.5454\n",
      "\n",
      "Validation:\n",
      "Epoch 9, Total loss = 1.3644314586639403     and accuracy of 0.5353\n",
      "\n",
      "\n",
      "Epoch 10:\n",
      "Iteration 5800:    with minibatch training loss = 1.2359319925308228    and accuracy of 0.4844\n",
      "Iteration 6000:    with minibatch training loss = 1.202131748199463    and accuracy of 0.5469\n",
      "Iteration 6200:    with minibatch training loss = 1.1664798259735107    and accuracy of 0.5312\n",
      "Epoch 10, Total loss = 1.2065948892593383     and accuracy of 0.5587\n",
      "\n",
      "Validation:\n",
      "Epoch 10, Total loss = 1.2737707546234132     and accuracy of 0.5439\n",
      "\n",
      "\n",
      "Epoch 11:\n",
      "Iteration 6400:    with minibatch training loss = 0.8168994784355164    and accuracy of 0.7188\n",
      "Iteration 6600:    with minibatch training loss = 1.2677764892578125    and accuracy of 0.5938\n",
      "Iteration 6800:    with minibatch training loss = 1.0659136772155762    and accuracy of 0.5781\n",
      "Epoch 11, Total loss = 1.1591932399749756     and accuracy of 0.5779\n",
      "\n",
      "Validation:\n",
      "Epoch 11, Total loss = 1.249878693008423     and accuracy of 0.5631\n",
      "\n",
      "\n",
      "Epoch 12:\n",
      "Iteration 7000:    with minibatch training loss = 1.2592310905456543    and accuracy of 0.5156\n",
      "Iteration 7200:    with minibatch training loss = 1.1471614837646484    and accuracy of 0.5625\n",
      "Iteration 7400:    with minibatch training loss = 1.1502379179000854    and accuracy of 0.5469\n",
      "Epoch 12, Total loss = 1.119238013458252     and accuracy of 0.5953\n",
      "\n",
      "Validation:\n",
      "Epoch 12, Total loss = 1.3782455810546874     and accuracy of 0.5503\n",
      "\n",
      "\n",
      "Epoch 13:\n",
      "Iteration 7600:    with minibatch training loss = 1.1961239576339722    and accuracy of 0.5625\n",
      "Iteration 7800:    with minibatch training loss = 1.1064260005950928    and accuracy of 0.5938\n",
      "Iteration 8000:    with minibatch training loss = 1.178140640258789    and accuracy of 0.6094\n",
      "Epoch 13, Total loss = 1.0918123038291931     and accuracy of 0.6072\n",
      "\n",
      "Validation:\n",
      "Epoch 13, Total loss = 1.283868021774292     and accuracy of 0.5626\n",
      "\n",
      "\n",
      "Epoch 14:\n",
      "Iteration 8200:    with minibatch training loss = 1.1890764236450195    and accuracy of 0.5781\n",
      "Iteration 8400:    with minibatch training loss = 1.0640684366226196    and accuracy of 0.6562\n",
      "Iteration 8600:    with minibatch training loss = 0.9858976602554321    and accuracy of 0.6094\n",
      "Epoch 14, Total loss = 1.0544990900039672     and accuracy of 0.6199\n",
      "\n",
      "Validation:\n",
      "Epoch 14, Total loss = 1.1170780036926269     and accuracy of 0.6148\n",
      "\n",
      "\n",
      "Epoch 15:\n",
      "Iteration 8800:    with minibatch training loss = 0.9755953550338745    and accuracy of 0.6875\n",
      "Iteration 9000:    with minibatch training loss = 0.7430965900421143    and accuracy of 0.7031\n",
      "Iteration 9200:    with minibatch training loss = 1.0851919651031494    and accuracy of 0.5625\n",
      "Epoch 15, Total loss = 1.0235498052597045     and accuracy of 0.6326\n",
      "\n",
      "Validation:\n",
      "Epoch 15, Total loss = 1.2062899566650391     and accuracy of 0.5925\n",
      "\n",
      "\n",
      "Epoch 16:\n",
      "Iteration 9400:    with minibatch training loss = 0.8629127144813538    and accuracy of 0.5938\n",
      "Iteration 9600:    with minibatch training loss = 0.9720408916473389    and accuracy of 0.6562\n",
      "Iteration 9800:    with minibatch training loss = 0.8477323055267334    and accuracy of 0.6406\n",
      "Epoch 16, Total loss = 1.001010739326477     and accuracy of 0.6388\n",
      "\n",
      "Validation:\n",
      "Epoch 16, Total loss = 1.1627271667480468     and accuracy of 0.6042\n",
      "\n",
      "\n",
      "Epoch 17:\n",
      "Iteration 10000:    with minibatch training loss = 0.9975922107696533    and accuracy of 0.6562\n",
      "Iteration 10200:    with minibatch training loss = 0.9289134740829468    and accuracy of 0.7031\n",
      "Iteration 10400:    with minibatch training loss = 0.9291567802429199    and accuracy of 0.7344\n",
      "Iteration 10600:    with minibatch training loss = 1.0077953338623047    and accuracy of 0.6094\n",
      "Epoch 17, Total loss = 0.980176104927063     and accuracy of 0.6452\n",
      "\n",
      "Validation:\n",
      "Epoch 17, Total loss = 1.0831533393859862     and accuracy of 0.6129\n",
      "\n",
      "\n",
      "Epoch 18:\n",
      "Iteration 10800:    with minibatch training loss = 0.8980271220207214    and accuracy of 0.7031\n",
      "Iteration 11000:    with minibatch training loss = 0.9869081974029541    and accuracy of 0.6875\n",
      "Iteration 11200:    with minibatch training loss = 0.6748409271240234    and accuracy of 0.7344\n",
      "Epoch 18, Total loss = 0.9551414703369141     and accuracy of 0.6583\n",
      "\n",
      "Validation:\n",
      "Epoch 18, Total loss = 1.227254716873169     and accuracy of 0.5938\n",
      "\n",
      "\n",
      "Epoch 19:\n",
      "Iteration 11400:    with minibatch training loss = 0.7025721669197083    and accuracy of 0.7344\n",
      "Iteration 11600:    with minibatch training loss = 0.8695119619369507    and accuracy of 0.7344\n",
      "Iteration 11800:    with minibatch training loss = 1.2003769874572754    and accuracy of 0.5938\n",
      "Epoch 19, Total loss = 0.9330314128875733     and accuracy of 0.6637\n",
      "\n",
      "Validation:\n",
      "Epoch 19, Total loss = 1.215049116897583     and accuracy of 0.5994\n",
      "\n",
      "\n",
      "Epoch 20:\n",
      "Iteration 12000:    with minibatch training loss = 0.7300456762313843    and accuracy of 0.7188\n",
      "Iteration 12200:    with minibatch training loss = 0.8669072389602661    and accuracy of 0.6875\n",
      "Iteration 12400:    with minibatch training loss = 0.7969156503677368    and accuracy of 0.6875\n",
      "Epoch 20, Total loss = 0.9179260935783387     and accuracy of 0.6713\n",
      "\n",
      "Validation:\n",
      "Epoch 20, Total loss = 1.2110426006317139     and accuracy of 0.5907\n",
      "\n",
      "\n",
      "Epoch 21:\n",
      "Iteration 12600:    with minibatch training loss = 1.2764863967895508    and accuracy of 0.5625\n",
      "Iteration 12800:    with minibatch training loss = 1.0836389064788818    and accuracy of 0.6094\n",
      "Iteration 13000:    with minibatch training loss = 0.8042086362838745    and accuracy of 0.7188\n",
      "Epoch 21, Total loss = 0.895734820652008     and accuracy of 0.6804\n",
      "\n",
      "Validation:\n",
      "Epoch 21, Total loss = 0.9764265792846679     and accuracy of 0.6636\n",
      "\n",
      "\n",
      "Epoch 22:\n",
      "Iteration 13200:    with minibatch training loss = 0.8961832523345947    and accuracy of 0.75\n",
      "Iteration 13400:    with minibatch training loss = 0.7930871844291687    and accuracy of 0.7344\n",
      "Iteration 13600:    with minibatch training loss = 0.8491608500480652    and accuracy of 0.7656\n",
      "Epoch 22, Total loss = 0.8756384286880493     and accuracy of 0.6871\n",
      "\n",
      "Validation:\n",
      "Epoch 22, Total loss = 0.9769282367706299     and accuracy of 0.6673\n",
      "\n",
      "\n",
      "Epoch 23:\n",
      "Iteration 13800:    with minibatch training loss = 0.8908716440200806    and accuracy of 0.7031\n",
      "Iteration 14000:    with minibatch training loss = 0.5056570768356323    and accuracy of 0.8281\n",
      "Iteration 14200:    with minibatch training loss = 0.9724413156509399    and accuracy of 0.6094\n",
      "Epoch 23, Total loss = 0.8573473788261413     and accuracy of 0.6947\n",
      "\n",
      "Validation:\n",
      "Epoch 23, Total loss = 0.9910048145294189     and accuracy of 0.6565\n",
      "\n",
      "\n",
      "Epoch 24:\n",
      "Iteration 14400:    with minibatch training loss = 0.7962648272514343    and accuracy of 0.7031\n",
      "Iteration 14600:    with minibatch training loss = 0.7627315521240234    and accuracy of 0.6719\n",
      "Iteration 14800:    with minibatch training loss = 0.7684979438781738    and accuracy of 0.7344\n",
      "Epoch 24, Total loss = 0.843966277217865     and accuracy of 0.6995\n",
      "\n",
      "Validation:\n",
      "Epoch 24, Total loss = 1.0239486579895019     and accuracy of 0.6537\n",
      "\n",
      "\n",
      "Epoch 25:\n",
      "Iteration 15000:    with minibatch training loss = 0.6898926496505737    and accuracy of 0.7812\n",
      "Iteration 15200:    with minibatch training loss = 0.8998453617095947    and accuracy of 0.7188\n",
      "Iteration 15400:    with minibatch training loss = 0.9768280386924744    and accuracy of 0.5312\n",
      "Iteration 15600:    with minibatch training loss = 0.7229114770889282    and accuracy of 0.7188\n",
      "Epoch 25, Total loss = 0.8313606758117675     and accuracy of 0.7044\n",
      "\n",
      "Validation:\n",
      "Epoch 25, Total loss = 0.987755867767334     and accuracy of 0.6551\n",
      "\n",
      "\n",
      "Epoch 26:\n",
      "Iteration 15800:    with minibatch training loss = 0.8488596677780151    and accuracy of 0.6719\n",
      "Iteration 16000:    with minibatch training loss = 0.8691285848617554    and accuracy of 0.7031\n",
      "Iteration 16200:    with minibatch training loss = 0.8573352098464966    and accuracy of 0.7188\n",
      "Epoch 26, Total loss = 0.810741524887085     and accuracy of 0.7124\n",
      "\n",
      "Validation:\n",
      "Epoch 26, Total loss = 0.967240263748169     and accuracy of 0.6707\n",
      "\n",
      "\n",
      "Epoch 27:\n",
      "Iteration 16400:    with minibatch training loss = 0.9021666049957275    and accuracy of 0.6562\n",
      "Iteration 16600:    with minibatch training loss = 0.7086076736450195    and accuracy of 0.7031\n",
      "Iteration 16800:    with minibatch training loss = 0.824326753616333    and accuracy of 0.7031\n",
      "Epoch 27, Total loss = 0.79177805352211     and accuracy of 0.7201\n",
      "\n",
      "Validation:\n",
      "Epoch 27, Total loss = 1.0537455242156983     and accuracy of 0.6403\n",
      "\n",
      "\n",
      "Epoch 28:\n",
      "Iteration 17000:    with minibatch training loss = 0.7799606919288635    and accuracy of 0.7188\n",
      "Iteration 17200:    with minibatch training loss = 0.7944685220718384    and accuracy of 0.6406\n",
      "Iteration 17400:    with minibatch training loss = 0.784141480922699    and accuracy of 0.75\n",
      "Epoch 28, Total loss = 0.7822156352043151     and accuracy of 0.7242\n",
      "\n",
      "Validation:\n",
      "Epoch 28, Total loss = 0.9648048839569092     and accuracy of 0.682\n",
      "\n",
      "\n",
      "Epoch 29:\n",
      "Iteration 17600:    with minibatch training loss = 0.807782769203186    and accuracy of 0.7031\n",
      "Iteration 17800:    with minibatch training loss = 0.5633624196052551    and accuracy of 0.7656\n",
      "Iteration 18000:    with minibatch training loss = 0.660449743270874    and accuracy of 0.7656\n",
      "Epoch 29, Total loss = 0.771978306055069     and accuracy of 0.7268\n",
      "\n",
      "Validation:\n",
      "Epoch 29, Total loss = 0.9671627464294433     and accuracy of 0.6781\n",
      "\n",
      "\n",
      "Epoch 30:\n",
      "Iteration 18200:    with minibatch training loss = 0.8331694602966309    and accuracy of 0.7344\n",
      "Iteration 18400:    with minibatch training loss = 0.6948517560958862    and accuracy of 0.75\n",
      "Iteration 18600:    with minibatch training loss = 0.6750717759132385    and accuracy of 0.7969\n",
      "Epoch 30, Total loss = 0.7591340361595154     and accuracy of 0.7318\n",
      "\n",
      "Validation:\n",
      "Epoch 30, Total loss = 0.9070553787231446     and accuracy of 0.6869\n",
      "\n",
      "\n",
      "Epoch 31:\n",
      "Iteration 18800:    with minibatch training loss = 0.5614467859268188    and accuracy of 0.8125\n",
      "Iteration 19000:    with minibatch training loss = 0.7892338037490845    and accuracy of 0.75\n",
      "Iteration 19200:    with minibatch training loss = 0.6332205533981323    and accuracy of 0.7969\n",
      "Epoch 31, Total loss = 0.7510010959148407     and accuracy of 0.7363\n",
      "\n",
      "Validation:\n",
      "Epoch 31, Total loss = 0.929600308227539     and accuracy of 0.6898\n",
      "\n",
      "\n",
      "Epoch 32:\n",
      "Iteration 19400:    with minibatch training loss = 0.647453784942627    and accuracy of 0.7344\n",
      "Iteration 19600:    with minibatch training loss = 0.8539847731590271    and accuracy of 0.7031\n",
      "Iteration 19800:    with minibatch training loss = 0.6044411659240723    and accuracy of 0.7344\n",
      "Epoch 32, Total loss = 0.7335259046077728     and accuracy of 0.7406\n",
      "\n",
      "Validation:\n",
      "Epoch 32, Total loss = 0.8631786140441895     and accuracy of 0.7063\n",
      "\n",
      "\n",
      "Epoch 33:\n",
      "Iteration 20000:    with minibatch training loss = 0.46923038363456726    and accuracy of 0.8594\n",
      "Iteration 20200:    with minibatch training loss = 0.7062426805496216    and accuracy of 0.7188\n",
      "Iteration 20400:    with minibatch training loss = 0.6604092121124268    and accuracy of 0.7969\n",
      "Iteration 20600:    with minibatch training loss = 0.7703324556350708    and accuracy of 0.7031\n",
      "Epoch 33, Total loss = 0.7262657772541046     and accuracy of 0.7409\n",
      "\n",
      "Validation:\n",
      "Epoch 33, Total loss = 0.8509417295455932     and accuracy of 0.7124\n",
      "\n",
      "\n",
      "Epoch 34:\n",
      "Iteration 20800:    with minibatch training loss = 0.8204206228256226    and accuracy of 0.7344\n",
      "Iteration 21000:    with minibatch training loss = 0.5483381748199463    and accuracy of 0.8281\n",
      "Iteration 21200:    with minibatch training loss = 0.5963454246520996    and accuracy of 0.7812\n",
      "Epoch 34, Total loss = 0.7117524306774139     and accuracy of 0.7484\n",
      "\n",
      "Validation:\n",
      "Epoch 34, Total loss = 0.8592065868377685     and accuracy of 0.7106\n",
      "\n",
      "\n",
      "Epoch 35:\n",
      "Iteration 21400:    with minibatch training loss = 0.7831382751464844    and accuracy of 0.75\n",
      "Iteration 21600:    with minibatch training loss = 0.6999372243881226    and accuracy of 0.7969\n",
      "Iteration 21800:    with minibatch training loss = 0.5840703248977661    and accuracy of 0.8125\n",
      "Epoch 35, Total loss = 0.7034682703495025     and accuracy of 0.7516\n",
      "\n",
      "Validation:\n",
      "Epoch 35, Total loss = 1.073201263809204     and accuracy of 0.6603\n",
      "\n",
      "\n",
      "Epoch 36:\n",
      "Iteration 22000:    with minibatch training loss = 0.389990895986557    and accuracy of 0.875\n",
      "Iteration 22200:    with minibatch training loss = 0.8065556883811951    and accuracy of 0.6406\n",
      "Iteration 22400:    with minibatch training loss = 0.8285099267959595    and accuracy of 0.7344\n",
      "Epoch 36, Total loss = 0.692340278673172     and accuracy of 0.756\n",
      "\n",
      "Validation:\n",
      "Epoch 36, Total loss = 0.8736188438415528     and accuracy of 0.708\n",
      "\n",
      "\n",
      "Epoch 37:\n",
      "Iteration 22600:    with minibatch training loss = 0.7730183601379395    and accuracy of 0.7188\n",
      "Iteration 22800:    with minibatch training loss = 0.7423796653747559    and accuracy of 0.7031\n",
      "Iteration 23000:    with minibatch training loss = 0.7588099241256714    and accuracy of 0.75\n",
      "Epoch 37, Total loss = 0.6845744438171387     and accuracy of 0.7583\n",
      "\n",
      "Validation:\n",
      "Epoch 37, Total loss = 0.871446337890625     and accuracy of 0.7143\n",
      "\n",
      "\n",
      "Epoch 38:\n",
      "Iteration 23200:    with minibatch training loss = 0.6773056983947754    and accuracy of 0.7812\n",
      "Iteration 23400:    with minibatch training loss = 0.5558042526245117    and accuracy of 0.7812\n",
      "Iteration 23600:    with minibatch training loss = 0.8482686281204224    and accuracy of 0.7031\n",
      "Epoch 38, Total loss = 0.6750483351230622     and accuracy of 0.7624\n",
      "\n",
      "Validation:\n",
      "Epoch 38, Total loss = 0.8685409141540528     and accuracy of 0.7044\n",
      "\n",
      "\n",
      "Epoch 39:\n",
      "Iteration 23800:    with minibatch training loss = 0.4979182183742523    and accuracy of 0.7656\n",
      "Iteration 24000:    with minibatch training loss = 0.6938158273696899    and accuracy of 0.7969\n",
      "Iteration 24200:    with minibatch training loss = 0.7127915620803833    and accuracy of 0.75\n",
      "Epoch 39, Total loss = 0.6623740743160248     and accuracy of 0.7686\n",
      "\n",
      "Validation:\n",
      "Epoch 39, Total loss = 0.8781974277496338     and accuracy of 0.7095\n",
      "\n",
      "\n",
      "Epoch 40:\n",
      "Iteration 24400:    with minibatch training loss = 0.4988689422607422    and accuracy of 0.7969\n",
      "Iteration 24600:    with minibatch training loss = 0.7723203897476196    and accuracy of 0.7188\n",
      "Iteration 24800:    with minibatch training loss = 0.840303897857666    and accuracy of 0.6875\n",
      "Epoch 40, Total loss = 0.662056905555725     and accuracy of 0.7679\n",
      "\n",
      "Validation:\n",
      "Epoch 40, Total loss = 1.0158781887054444     and accuracy of 0.6692\n",
      "\n",
      "\n",
      "Epoch 41:\n",
      "Iteration 25000:    with minibatch training loss = 0.49344494938850403    and accuracy of 0.8281\n",
      "Iteration 25200:    with minibatch training loss = 0.5657559633255005    and accuracy of 0.8125\n",
      "Iteration 25400:    with minibatch training loss = 0.6053491234779358    and accuracy of 0.7656\n",
      "Iteration 25600:    with minibatch training loss = 0.5314540863037109    and accuracy of 0.8438\n",
      "Epoch 41, Total loss = 0.6528724910736085     and accuracy of 0.7707\n",
      "\n",
      "Validation:\n",
      "Epoch 41, Total loss = 0.8861900840759277     and accuracy of 0.7052\n",
      "\n",
      "\n",
      "Epoch 42:\n",
      "Iteration 25800:    with minibatch training loss = 0.560484766960144    and accuracy of 0.7812\n",
      "Iteration 26000:    with minibatch training loss = 0.5620672106742859    and accuracy of 0.8125\n",
      "Iteration 26200:    with minibatch training loss = 0.6760261058807373    and accuracy of 0.8125\n",
      "Epoch 42, Total loss = 0.6390090689659119     and accuracy of 0.775\n",
      "\n",
      "Validation:\n",
      "Epoch 42, Total loss = 0.9163080661773682     and accuracy of 0.7029\n",
      "\n",
      "\n",
      "Epoch 43:\n",
      "Iteration 26400:    with minibatch training loss = 0.7036598920822144    and accuracy of 0.7656\n",
      "Iteration 26600:    with minibatch training loss = 0.5071103572845459    and accuracy of 0.8594\n",
      "Iteration 26800:    with minibatch training loss = 0.8234272599220276    and accuracy of 0.7344\n",
      "Epoch 43, Total loss = 0.6336787344932556     and accuracy of 0.7759\n",
      "\n",
      "Validation:\n",
      "Epoch 43, Total loss = 0.8111881942749023     and accuracy of 0.7277\n",
      "\n",
      "\n",
      "Epoch 44:\n",
      "Iteration 27000:    with minibatch training loss = 0.36783215403556824    and accuracy of 0.8594\n",
      "Iteration 27200:    with minibatch training loss = 0.5333314538002014    and accuracy of 0.8125\n",
      "Iteration 27400:    with minibatch training loss = 0.7547684907913208    and accuracy of 0.7656\n",
      "Epoch 44, Total loss = 0.6268391372680664     and accuracy of 0.7805\n",
      "\n",
      "Validation:\n",
      "Epoch 44, Total loss = 0.8946588108062744     and accuracy of 0.7097\n",
      "\n",
      "\n",
      "Epoch 45:\n",
      "Iteration 27600:    with minibatch training loss = 0.550494909286499    and accuracy of 0.7656\n",
      "Iteration 27800:    with minibatch training loss = 0.687298595905304    and accuracy of 0.7344\n",
      "Iteration 28000:    with minibatch training loss = 0.5846767425537109    and accuracy of 0.7656\n",
      "Epoch 45, Total loss = 0.6177062780380249     and accuracy of 0.7832\n",
      "\n",
      "Validation:\n",
      "Epoch 45, Total loss = 0.8309498918533326     and accuracy of 0.7259\n",
      "\n",
      "\n",
      "Epoch 46:\n",
      "Iteration 28200:    with minibatch training loss = 0.6031227707862854    and accuracy of 0.8125\n",
      "Iteration 28400:    with minibatch training loss = 0.6710546016693115    and accuracy of 0.7656\n",
      "Iteration 28600:    with minibatch training loss = 0.7355890870094299    and accuracy of 0.7812\n",
      "Epoch 46, Total loss = 0.6141237183570862     and accuracy of 0.7826\n",
      "\n",
      "Validation:\n",
      "Epoch 46, Total loss = 0.8776638904571533     and accuracy of 0.7117\n",
      "\n",
      "\n",
      "Epoch 47:\n",
      "Iteration 28800:    with minibatch training loss = 0.5645958781242371    and accuracy of 0.8438\n",
      "Iteration 29000:    with minibatch training loss = 0.5274074077606201    and accuracy of 0.8125\n",
      "Iteration 29200:    with minibatch training loss = 0.4572463929653168    and accuracy of 0.7969\n",
      "Epoch 47, Total loss = 0.600720545053482     and accuracy of 0.7892\n",
      "\n",
      "Validation:\n",
      "Epoch 47, Total loss = 0.8991718589782715     and accuracy of 0.7135\n",
      "\n",
      "\n",
      "Epoch 48:\n",
      "Iteration 29400:    with minibatch training loss = 0.7010633945465088    and accuracy of 0.75\n",
      "Iteration 29600:    with minibatch training loss = 0.6825953722000122    and accuracy of 0.8125\n",
      "Iteration 29800:    with minibatch training loss = 0.3564642667770386    and accuracy of 0.8438\n",
      "Epoch 48, Total loss = 0.5915426495552063     and accuracy of 0.7898\n",
      "\n",
      "Validation:\n",
      "Epoch 48, Total loss = 0.8296331245422364     and accuracy of 0.7276\n",
      "\n",
      "\n",
      "Epoch 49:\n",
      "Iteration 30000:    with minibatch training loss = 0.6215131282806396    and accuracy of 0.75\n",
      "Iteration 30200:    with minibatch training loss = 0.3919259309768677    and accuracy of 0.8281\n",
      "Iteration 30400:    with minibatch training loss = 0.6721567511558533    and accuracy of 0.7188\n",
      "Iteration 30600:    with minibatch training loss = 0.6618064641952515    and accuracy of 0.7812\n",
      "Epoch 49, Total loss = 0.5901764716625214     and accuracy of 0.7933\n",
      "\n",
      "Validation:\n",
      "Epoch 49, Total loss = 0.9097474113464356     and accuracy of 0.7111\n",
      "\n",
      "\n",
      "Epoch 50:\n",
      "Iteration 30800:    with minibatch training loss = 0.6174084544181824    and accuracy of 0.75\n",
      "Iteration 31000:    with minibatch training loss = 0.5870949029922485    and accuracy of 0.7969\n",
      "Iteration 31200:    with minibatch training loss = 0.5694771409034729    and accuracy of 0.8438\n",
      "Epoch 50, Total loss = 0.5758477771759033     and accuracy of 0.7979\n",
      "\n",
      "Validation:\n",
      "Epoch 50, Total loss = 0.8598631744384766     and accuracy of 0.7277\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7CeEmFlI8oHCLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH8e6emmaSvXQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph() # clear old variables\n",
    "\n",
    "# The first dim is None, and it is set automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "pred = complex_model(X, y, is_training)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(tf.one_hot(y, 10), pred) # define our loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3) # Adam optimizer with 1e-3 learning rate\n",
    "\n",
    "# batch normalization in tensorflow requires this extra dependency\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) \n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "#Below we'll create a session and train the model over 50 epochs.    \n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\") as dev: #training our model on GPU\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        run_model(sess, pred, X_train, y_train, X_val, y_val, 50, \n",
    "                  64, 200, plot_losses=True, plot_accuracies=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpMdnEJDbCPb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNNs_with_tf.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
